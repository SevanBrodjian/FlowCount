{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c757bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, random, math, pickle, json, shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import torch, torchvision\n",
    "from torchinfo import summary\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89ec2224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to → C:\\Users\\Owner\\Documents\\FlowCount\\exp_20250602_102312\n"
     ]
    }
   ],
   "source": [
    "DATA_FILE          = \"dots100k_128.pt\"   # path to the .pt with {\"frames\",\"disp\"}\n",
    "BATCH_SZ           = 256\n",
    "NUM_EPOCHS         = 15\n",
    "LR                 = 2e-4\n",
    "WEIGHT_DECAY       = 1e-4\n",
    "RESNET_DEPTH       = 18       # choose 18, 34, 50, 101 …\n",
    "PRETRAINED         = False    # if True, load ImageNet weights then patch 1st conv\n",
    "USE_GRAYSCALE      = False    # if True, convert f0,f1,diff to 1-channel each\n",
    "\n",
    "TRAIN_FRACTION     = 0.8      # 80 % train, 10 % val, 10 % test\n",
    "VAL_FRACTION       = 0.1\n",
    "\n",
    "DEVICE             = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Experiment folder\n",
    "EXP_DIR = Path(f\"exp_{datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "EXP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Logging to → {EXP_DIR.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4900ead7",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "288c48ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotPairDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Each item:\n",
    "        x : Tensor  (C,H,W)  where C = 9 (RGB) or 3 (grayscale)\n",
    "        y : scalar  int32    total horizontal displacement\n",
    "    \"\"\"\n",
    "    def __init__(self, frames_uint8, disp_int32, grayscale=False):\n",
    "        assert frames_uint8.dtype == torch.uint8\n",
    "        self.F   = frames_uint8\n",
    "        self.disp = disp_int32\n",
    "        self.gray = grayscale\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.disp.shape[0]\n",
    "\n",
    "    def _to_float(self, img_uint8):\n",
    "        return img_uint8.float().div_(255.)  # → [0,1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        f0_u8 = self.F[idx]       # (3,H,W) uint8\n",
    "        f1_u8 = self.F[idx+1]\n",
    "        diff  = (f1_u8.to(torch.int16) - f0_u8.to(torch.int16)).clamp_(-255,255)\n",
    "        diff_u8 = (diff + 255).to(torch.uint8)   # shift to 0..510, still uint8\n",
    "\n",
    "        if not self.gray:\n",
    "            x = torch.cat([f0_u8, f1_u8, diff_u8], dim=0)   # (9,H,W)\n",
    "        else:\n",
    "            to_gray = lambda im: (0.299*im[0] + 0.587*im[1] + 0.114*im[2]).unsqueeze(0)\n",
    "            g0 = to_gray(f0_u8); g1 = to_gray(f1_u8); gd = to_gray(diff_u8)\n",
    "            x = torch.cat([g0, g1, gd], dim=0)              # (3,H,W)\n",
    "\n",
    "        x = self._to_float(x)\n",
    "        y = self.disp[idx].float()                # regression target\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cabcc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_2088\\3202958625.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  raw = torch.load(DATA_FILE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes — train: 80000, val: 10000, test: 10000\n"
     ]
    }
   ],
   "source": [
    "raw = torch.load(DATA_FILE)\n",
    "frames_u8, disp_i32 = raw[\"frames\"], raw[\"disp\"]\n",
    "\n",
    "full_ds   = DotPairDataset(frames_u8, disp_i32, grayscale=USE_GRAYSCALE)\n",
    "\n",
    "n_total   = len(full_ds)\n",
    "n_train   = int(TRAIN_FRACTION * n_total)\n",
    "n_val     = int(VAL_FRACTION   * n_total)\n",
    "n_test    = n_total - n_train - n_val\n",
    "\n",
    "train_ds, val_ds, test_ds = random_split(full_ds, [n_train, n_val, n_test],\n",
    "                                         generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "train_ld = DataLoader(train_ds, batch_size=BATCH_SZ, shuffle=True,\n",
    "                      num_workers=4, pin_memory=True)\n",
    "val_ld   = DataLoader(val_ds,   batch_size=BATCH_SZ, shuffle=False,\n",
    "                      num_workers=4, pin_memory=True)\n",
    "test_ld  = DataLoader(test_ds,  batch_size=BATCH_SZ, shuffle=False,\n",
    "                      num_workers=4, pin_memory=True)\n",
    "\n",
    "print(f\"Dataset sizes — train: {n_train}, val: {n_val}, test: {n_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b548e12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.9490196..0.9490196].\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = random.randrange(len(full_ds))\n",
    "(pair, label) = full_ds[idx]\n",
    "f0 = pair[0:3].permute(1, 2, 0).numpy()  # (H,W,3)\n",
    "f1 = pair[3:6].permute(1, 2, 0).numpy()\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Frame t\")\n",
    "plt.imshow(f0)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Frame t+1\")\n",
    "plt.imshow(f1)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(f\"Δx = {int(label.item())} px\")\n",
    "diff = (f1 - f0)\n",
    "plt.imshow(diff)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0513b16",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39bee59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "ResNet                                   --\n",
       "├─Conv2d: 1-1                            28,224\n",
       "├─BatchNorm2d: 1-2                       128\n",
       "├─ReLU: 1-3                              --\n",
       "├─MaxPool2d: 1-4                         --\n",
       "├─Sequential: 1-5                        --\n",
       "│    └─BasicBlock: 2-1                   --\n",
       "│    │    └─Conv2d: 3-1                  36,864\n",
       "│    │    └─BatchNorm2d: 3-2             128\n",
       "│    │    └─ReLU: 3-3                    --\n",
       "│    │    └─Conv2d: 3-4                  36,864\n",
       "│    │    └─BatchNorm2d: 3-5             128\n",
       "│    └─BasicBlock: 2-2                   --\n",
       "│    │    └─Conv2d: 3-6                  36,864\n",
       "│    │    └─BatchNorm2d: 3-7             128\n",
       "│    │    └─ReLU: 3-8                    --\n",
       "│    │    └─Conv2d: 3-9                  36,864\n",
       "│    │    └─BatchNorm2d: 3-10            128\n",
       "├─Sequential: 1-6                        --\n",
       "│    └─BasicBlock: 2-3                   --\n",
       "│    │    └─Conv2d: 3-11                 73,728\n",
       "│    │    └─BatchNorm2d: 3-12            256\n",
       "│    │    └─ReLU: 3-13                   --\n",
       "│    │    └─Conv2d: 3-14                 147,456\n",
       "│    │    └─BatchNorm2d: 3-15            256\n",
       "│    │    └─Sequential: 3-16             8,448\n",
       "│    └─BasicBlock: 2-4                   --\n",
       "│    │    └─Conv2d: 3-17                 147,456\n",
       "│    │    └─BatchNorm2d: 3-18            256\n",
       "│    │    └─ReLU: 3-19                   --\n",
       "│    │    └─Conv2d: 3-20                 147,456\n",
       "│    │    └─BatchNorm2d: 3-21            256\n",
       "├─Sequential: 1-7                        --\n",
       "│    └─BasicBlock: 2-5                   --\n",
       "│    │    └─Conv2d: 3-22                 294,912\n",
       "│    │    └─BatchNorm2d: 3-23            512\n",
       "│    │    └─ReLU: 3-24                   --\n",
       "│    │    └─Conv2d: 3-25                 589,824\n",
       "│    │    └─BatchNorm2d: 3-26            512\n",
       "│    │    └─Sequential: 3-27             33,280\n",
       "│    └─BasicBlock: 2-6                   --\n",
       "│    │    └─Conv2d: 3-28                 589,824\n",
       "│    │    └─BatchNorm2d: 3-29            512\n",
       "│    │    └─ReLU: 3-30                   --\n",
       "│    │    └─Conv2d: 3-31                 589,824\n",
       "│    │    └─BatchNorm2d: 3-32            512\n",
       "├─Sequential: 1-8                        --\n",
       "│    └─BasicBlock: 2-7                   --\n",
       "│    │    └─Conv2d: 3-33                 1,179,648\n",
       "│    │    └─BatchNorm2d: 3-34            1,024\n",
       "│    │    └─ReLU: 3-35                   --\n",
       "│    │    └─Conv2d: 3-36                 2,359,296\n",
       "│    │    └─BatchNorm2d: 3-37            1,024\n",
       "│    │    └─Sequential: 3-38             132,096\n",
       "│    └─BasicBlock: 2-8                   --\n",
       "│    │    └─Conv2d: 3-39                 2,359,296\n",
       "│    │    └─BatchNorm2d: 3-40            1,024\n",
       "│    │    └─ReLU: 3-41                   --\n",
       "│    │    └─Conv2d: 3-42                 2,359,296\n",
       "│    │    └─BatchNorm2d: 3-43            1,024\n",
       "├─AdaptiveAvgPool2d: 1-9                 --\n",
       "├─Linear: 1-10                           513\n",
       "=================================================================\n",
       "Total params: 11,195,841\n",
       "Trainable params: 11,195,841\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_resnet(depth=18, in_channels=9, pretrained=False):\n",
    "    factory = {\n",
    "        18:  torchvision.models.resnet18,\n",
    "        34:  torchvision.models.resnet34,\n",
    "        50:  torchvision.models.resnet50,\n",
    "        101: torchvision.models.resnet101,\n",
    "        152: torchvision.models.resnet152,\n",
    "    }[depth]\n",
    "\n",
    "    model = factory(weights=\"IMAGENET1K_V1\" if pretrained else None)\n",
    "\n",
    "    # Patch the first conv if channel count differs\n",
    "    if in_channels != 3:\n",
    "        w = model.conv1.weight\n",
    "        model.conv1 = nn.Conv2d(in_channels, w.shape[0],\n",
    "                                kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        if pretrained:\n",
    "            # Kaiming init for new conv\n",
    "            nn.init.kaiming_normal_(model.conv1.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "\n",
    "    # Replace classifier with 1-unit head for regression\n",
    "    model.fc = nn.Linear(model.fc.in_features, 1)\n",
    "    return model\n",
    "\n",
    "C_IN   = 3 if USE_GRAYSCALE else 9\n",
    "net    = get_resnet(RESNET_DEPTH, in_channels=C_IN, pretrained=PRETRAINED).to(DEVICE)\n",
    "criterion = nn.L1Loss()\n",
    "optim     = torch.optim.AdamW(net.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "summary(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5cc74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, loader, train=True):\n",
    "    if train: model.train()\n",
    "    else:     model.eval()\n",
    "\n",
    "    total_loss, n_samples = 0.0, 0\n",
    "    with torch.set_grad_enabled(train):\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE).unsqueeze(1)  # (B,1)\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            if train:\n",
    "                optim.zero_grad(set_to_none=True)\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            n_samples  += x.size(0)\n",
    "    return total_loss / n_samples    # MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7090df9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m train_curve, val_curve \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m      2\u001b[0m best_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      5\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      6\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m run_epoch(net, train_ld, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\diffusion\\Lib\\site-packages\\tqdm\\notebook.py:234\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m unit_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    233\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m*\u001b[39m unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n\u001b[1;32m--> 234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\diffusion\\Lib\\site-packages\\tqdm\\notebook.py:108\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[0;32m    110\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m IProgress(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mtotal)\n",
      "\u001b[1;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "train_curve, val_curve = [], []\n",
    "best_val = float(\"inf\")\n",
    "\n",
    "for epoch in trange(1, NUM_EPOCHS+1):\n",
    "    t0 = time.time()\n",
    "    tr_loss = run_epoch(net, train_ld, train=True)\n",
    "    val_loss = run_epoch(net, val_ld,   train=False)\n",
    "\n",
    "    train_curve.append(tr_loss)\n",
    "    val_curve.append(val_loss)\n",
    "\n",
    "    # -- console log\n",
    "    print(f\"[{epoch:02d}/{NUM_EPOCHS}]  \"\n",
    "          f\"train MAE {tr_loss:.4f} | val MAE {val_loss:.4f}  \"\n",
    "          f\"({time.time()-t0:.1f}s)\")\n",
    "\n",
    "    # -- checkpointing\n",
    "    last_path = EXP_DIR / \"last_weights.pt\"\n",
    "    best_path = EXP_DIR / \"best_weights.pt\"\n",
    "    torch.save({\"epoch\": epoch,\n",
    "                \"state_dict\": net.state_dict(),\n",
    "                \"train_loss\": tr_loss,\n",
    "                \"val_loss\": val_loss},\n",
    "               last_path)\n",
    "\n",
    "    if val_loss < best_val:\n",
    "        best_val = val_loss\n",
    "        shutil.copy(last_path, best_path)\n",
    "        print(f\"  ↳ new best! ({best_val:.4f}) checkpointed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
